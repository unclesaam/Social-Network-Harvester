Ceci est un journal du travail effectué dans le cadre de la mise à niveau de la plateforme Aspira. Auteur: Samuel Cloutier

22 fevrier 2015:
- Installation d'un environnement virtuel python 2.7.9 avec les modules requis à la plateforme ASPIRA
- Installation locale d'un serveur MySQL afin de déservir la base de données locale
- Premier lancement local du serveur avec Django
- Tentative de créer un premier objet twitter-scrapper (sans succès, pas assez de comprehension du fonctionnement)
- Fin de la journée

2 mars 2015: 
- Étude du fonctionnement original de python-twitter. Le module requis ne semble pas être le même que celui en local. Le module "Twython" n'existe pas.
- Recherche en ligne des différences au niveau du nouvel API de twitter
- Test du module récent en utilisant Aspira, avec un compte twitter fais pour la cause, avec une appli. Aucun tweet harvesté, sans surprise.
- Fin de la journée (1h)

6 mars 2015:
- Fork du repository Git et installation de gitHub for windows
- Étude du fonctionnement de la base de donnés et des twitter-views
- Test du module python-twitter à part sans Aspira
- run des tests pré-assemblés du module (les tests sont outdatés et doivent être faits un à un)
- Fin de journée (3h)

9 mars 2015:
- comprehension du fonctionnement des customs-commands de manage.py (crontw, cronfb, etc.)
- Étude du fonctionnement du protocole d'authentification OAuth 1.0
- Correction des problèmes de mise à jours du status des scrappers (remaining hits, hourly limit, etc.)
- Débuggage général des methodes dans twitterch.py et twittermodel.py (a terminer)
- fin de journée (7h)

10 mars 2015:
- Debuggage des problèmes reliés aux types de données de la DB.
- Potentiel besoin d'ajouter des fields. Sera à considérer si ultimement nécéssaire
- fin de journée (2h)

11 mars 2015: 
- Mise en place d'un logger pour le débuging des fichiers (différent du logger déjà présent)
- Réglé petit problème dans le template twitter.html
- fin de journée (1h)

14 mars 2015:
- Il sera préférable à long terme de n'utiliser que le module Twython pour les api calls. Celui-ci est beaucoup plus complet et pourrait éventuellement supporter le stream API. Je considère donc de créer de nouveaux modèles pour Twitter, avec une toute nouvelle procédure de scrapping.
- En attendant, réparation provisoire de l'ancien protocole twitter. (fonctionnel, mais non-optimal et avec quelque bugs)
- Ajout de la liste des récents status postés dans la page d'acceuil Twitter
- ajout d'une section "Tw statuses" à la page admin
-fin de journée (8h)

23 mars 2015:
- Recherche de problèmes avec les scrappers de Facebook (module "resource" supporté seulement sous Unix)
- Réparation générale des templates de twitter
- Fin de journée (5h)

24 mars 2015:
- Installation des modules requis au scrapping de facebook (remplacement du module resource par psutil)
- Étude du fonctionnement de Fandjango et du Graph API de FB
- Fin de journée (1h)

3 avril 2015:
- Set up de fandjango, test des fonctionnalités
- Installation d'Apache (about time, I know...)
- Mise en place d'un certificat SSL via apache (got to learn first)
- Fin de journée (3h)

27 avril 2015:
- Fouillage dans la doc de google data, afin de faire fonctionner youtube
- Création d'un harvester, app sur mon compte,  etc.
- Test des fonctionnalités et débugging
- fin de journee (5h)

28 avril 2015:
- Continuation du 27 avril.
- Débug de la procédure d'ajout de nouveaux users
- Grattage de tete general
- fin de journée (5h)

29 - 30  et 31 avril 2015:
- Le scrapping de youtube fonctionne (presque) sans bugs.
- TODO:
	- debugger "video watch count"  et "view count" qui ne s'updatent pas
	- Mettre a jour le youtube player dans la page des videos (download des videos dans la db??)
	- Patching des erreurs occasionnelles (unicode errors, etc.)
- fins de journées (5h) (5h) (5h)

1 mai 2015:
- Rencontre avec Pier-Yves a propos de son bébé:
- Questions a poser:
	- Comment utiliser FanDjango?
	- Fandjango user
	- différentes versions de run_harvester ?
	- Download des videos youtube?
	- Serveur test Aspira
- Points retenus de la rencontre:
	- ID Facebook change risque de rendre la base de données actuelle obsolete au niveau des IDs
	- FanUser peut être importé de l'ancienne base de donnés
	- Probable nécéssité de recodder l'acces au token Facebook au complet
	- Connection au VPN du FSS requise pour accéder au SNH
- Listage des tâches a effectuer dans le cadre du stage

4 mai 2015:
- Installation de mon moniteur au bureau du GRCP
- Tentative d'obtention d'un token Facebook a partir d'un serveur de developpement
- debuggage et compréhension de Fandjango
- Fin de journée (5h)

5 mai 2015:
- Setup de django en mode SSL afin de pouvoir communiquer avec Facebook en https (difficultés rencontrées)
- Essai de fowarder les connections entrantes en utilisant stunel, sans succès.
- Essaie d'installer des modules django qui le font a ma place: Tous sont en python3... Je pense en customiser un pour mes besoins en python27
- Fin de journée (5h)

6, 7, 8 mai 2015:
- Implémentation du système de connection d'utilisateur Facebook (app, token, etc.)
- Changement du protocole d'appels au API par le harvester (retrait de fandjango)
- Essais et tests, implémentation manuelle des appels "batch"
- fins de journées (5h) (3h) (5h)

18 mai 2015:
- Rédaction de demande d'accès d'autorisations étendues pour l'app Facebook
- Amélioration de ma structure de debuggage
- Debuggage partiel de Facebook
- Fin de journée (6h)

19 mai 2015:
- Setup de la connection Web-VPN avec AnyConnect
- Débugging de Facebook, still...
- Fin de journée (5h)

20 - 21 mai 2015:
- Débugging de Facebook, fonctionnel, mise au point de détails
- Fin de journée (6h), (6h)

22 mai 2015:
- Fix d'un problème avec Unicode dans la DB SQL causant certain comments à être rejetés (caratères non-UTF-8)
- Remise au point de la compatibilité des méthodes Update_from_facebook() afin de collecter le plus de data possible.
- fin de journée (6h)

25 mai 2015:
- Graph API throttle les requests lorsque l'app en fait trop. Ma limite est tombée de 250 à moins de 50 par call.
- Ajustement automatique de la limite lorsqu'une erreur du genre survient.
- Acces au serveur-test du SNH. Tentative de setup de la base de donné MySQL, afins d'y avoir acces à distance, faire des backups, etc.
- fin de journée (7h)

26 mai 2015:
- Connection à distance à la base de données du serveur-test. 
- Setup adéquat de Apache sur le serveur-test et debuggage du serveur
- Serveur-test en ligne!
- fin de journée (8h)

28 mai 2015:
- Setup des harvesters sur le serveur-test (Youtube, Facebook et Twiter) et tests
- Mise en place des cron-jobs
- tests
- fin de journée (6h)

30 mai 2015:
- Fix de la procédure de paging de Twitter
- Tests
- fin de journée (6h)

1 juin 2015:
- Optimisation du code twitter, afin d'utiliser toute les ressources disponibles pour chaque app et accélérer la collecte
- fin de journée (6h)

2 juin 2015:
- Optimisation de l'utilisation des ressources Twitter
- Code d'un algo permettant de collecter les infos de tout les utilisateurs (pas juste ceux harvestés)
- fin de journée (6h)