Ceci est un journal du travail effectué dans le cadre de la mise à niveau de la plateforme Aspira. Auteur: Samuel Cloutier

22 fevrier 2015:
- Installation d'un environnement virtuel python 2.7.9 avec les modules requis à la plateforme ASPIRA
- Installation locale d'un serveur MySQL afin de déservir la base de données locale
- Premier lancement local du serveur avec Django
- Tentative de créer un premier objet twitter-scrapper (sans succès, pas assez de comprehension du fonctionnement)
- Fin de la journée

2 mars 2015: 
- Étude du fonctionnement original de python-twitter. Le module requis ne semble pas être le même que celui en local. Le module "Twython" n'existe pas.
- Recherche en ligne des différences au niveau du nouvel API de twitter
- Test du module récent en utilisant Aspira, avec un compte twitter fais pour la cause, avec une appli. Aucun tweet harvesté, sans surprise.
- Fin de la journée (1h)

6 mars 2015:
- Fork du repository Git et installation de gitHub for windows
- Étude du fonctionnement de la base de donnés et des twitter-views
- Test du module python-twitter à part sans Aspira
- run des tests pré-assemblés du module (les tests sont outdatés et doivent être faits un à un)
- Fin de journée (3h)

9 mars 2015:
- comprehension du fonctionnement des customs-commands de manage.py (crontw, cronfb, etc.)
- Étude du fonctionnement du protocole d'authentification OAuth 1.0
- Correction des problèmes de mise à jours du status des scrappers (remaining hits, hourly limit, etc.)
- Débuggage général des methodes dans twitterch.py et twittermodel.py (a terminer)
- fin de journée (7h)

10 mars 2015:
- Debuggage des problèmes reliés aux types de données de la DB.
- Potentiel besoin d'ajouter des fields. Sera à considérer si ultimement nécéssaire
- fin de journée (2h)

11 mars 2015: 
- Mise en place d'un logger pour le débuging des fichiers (différent du logger déjà présent)
- Réglé petit problème dans le template twitter.html
- fin de journée (1h)

14 mars 2015:
- Il sera préférable à long terme de n'utiliser que le module Twython pour les api calls. Celui-ci est beaucoup plus complet et pourrait éventuellement supporter le stream API. Je considère donc de créer de nouveaux modèles pour Twitter, avec une toute nouvelle procédure de scrapping.
- En attendant, réparation provisoire de l'ancien protocole twitter. (fonctionnel, mais non-optimal et avec quelque bugs)
- Ajout de la liste des récents status postés dans la page d'acceuil Twitter
- ajout d'une section "Tw statuses" à la page admin
-fin de journée (8h)

23 mars 2015:
- Recherche de problèmes avec les scrappers de Facebook (module "resource" supporté seulement sous Unix)
- Réparation générale des templates de twitter
- Fin de journée (5h)

24 mars 2015:
- Installation des modules requis au scrapping de facebook (remplacement du module resource par psutil)
- Étude du fonctionnement de Fandjango et du Graph API de FB
- Fin de journée (1h)

3 avril 2015:
- Set up de fandjango, test des fonctionnalités
- Installation d'Apache (about time, I know...)
- Mise en place d'un certificat SSL via apache (got to learn first)
- Fin de journée (3h)

27 avril 2015:
- Fouillage dans la doc de google data, afin de faire fonctionner youtube
- Création d'un harvester, app sur mon compte,  etc.
- Test des fonctionnalités et débugging
- fin de journee (5h)

28 avril 2015:
- Continuation du 27 avril.
- Débug de la procédure d'ajout de nouveaux users
- Grattage de tete general
- fin de journée (5h)

29 - 30  et 31 avril 2015:
- Le scrapping de youtube fonctionne (presque) sans bugs.
- TODO:
	- debugger "video watch count"  et "view count" qui ne s'updatent pas
	- Mettre a jour le youtube player dans la page des videos (download des videos dans la db??)
	- Patching des erreurs occasionnelles (unicode errors, etc.)
- fins de journées (5h) (5h) (5h)

1 avril 2015:
- Rencontre avec Pier-Yves a propos de son bébé:
- Questions a poser:
	- Comment utiliser FanDjango?
	- Fandjango user
	- différentes versions de run_harvester ?
	- Download des videos youtube?
	- Serveur test Aspira
- Points retenus de la rencontre:
	- ID Facebook change risque de rendre la base de données actuelle obsolete au niveau des IDs
	- FanUser peut être importé de l'ancienne base de donnés
	- Probable nécéssité de recodder l'acces au token Facebook au complet
	- Connection au VPN du FSS requise pour accéder au SNH
- Listage des tâches a effectuer dans le cadre du stage

4 avril 2015:
- Installation de mon moniteur au bureau du GRCP
- Tentative d'obtention d'un token Facebook a partir d'un serveur de developpement
- debuggage et compréhension de Fandjango
- Fin de journée (5h)

5 avril 2015:
- Setup de django en mode SSL afin de pouvoir communiquer avec Facebook en https (difficultés rencontrées)
- Essai de fowarder les connections entrantes en utilisant stunel, sans succès.
- Essaie d'installer des modules django qui le font a ma place: Tous sont en python3... Je pense en customiser un pour mes besoins en python27
- Fin de journée (5h)

6, 7, 8 avril 2015:
- Implémentation du système de connection d'utilisateur Facebook (app, token, etc.)
- Changement du protocole d'appels au API par le harvester (retrait de fandjango)
- Essais et tests, implémentation manuelle des appels "batch"
- fins de journées (5h) (3h) (5h)

18 avril 2015:
- Rédaction de demande d'accès d'autorisations étendues pour l'app Facebook
- Amélioration de ma structure de debuggage
- Debuggage partiel de Facebook
- Fin de journée (6h)

19 avril 2015:
- Setup de la connection Web-VPN avec AnyConnect
- Débugging de Facebook, still...
- Fin de journée (5h)

20 - 21 avril 2015:
- Débugging de Facebook, fonctionnel, mise au point de détails
- Fin de journée (6h), (6h)
