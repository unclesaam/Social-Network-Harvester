Ceci est un journal du travail effectué dans le cadre de la mise à niveau de la plateforme Aspira. Auteur: Samuel Cloutier

22 fevrier 2015:
- Installation d'un environnement virtuel python 2.7.9 avec les modules requis à la plateforme ASPIRA
- Installation locale d'un serveur MySQL afin de déservir la base de données locale
- Premier lancement local du serveur avec Django
- Tentative de créer un premier objet twitter-scrapper (sans succès, pas assez de comprehension du fonctionnement)
- Fin de la journée

2 mars 2015: 
- Étude du fonctionnement original de python-twitter. Le module requis ne semble pas être le même que celui en local. Le module "Twython" n'existe pas.
- Recherche en ligne des différences au niveau du nouvel API de twitter
- Test du module récent en utilisant Aspira, avec un compte twitter fais pour la cause, avec une appli. Aucun tweet harvesté, sans surprise.
- Fin de la journée (1h)

6 mars 2015:
- Fork du repository Git et installation de gitHub for windows
- Étude du fonctionnement de la base de donnés et des twitter-views
- Test du module python-twitter à part sans Aspira
- run des tests pré-assemblés du module (les tests sont outdatés et doivent être faits un à un)
- Fin de journée (3h)

9 mars 2015:
- comprehension du fonctionnement des customs-commands de manage.py (crontw, cronfb, etc.)
- Étude du fonctionnement du protocole d'authentification OAuth 1.0
- Correction des problèmes de mise à jours du status des scrappers (remaining hits, hourly limit, etc.)
- Débuggage général des methodes dans twitterch.py et twittermodel.py (a terminer)
- fin de journée (7h)

10 mars 2015:
- Debuggage des problèmes reliés aux types de données de la DB.
- Potentiel besoin d'ajouter des fields. Sera à considérer si ultimement nécéssaire
- fin de journée (2h)

11 mars 2015: 
- Mise en place d'un logger pour le débuging des fichiers (différent du logger déjà présent)
- Réglé petit problème dans le template twitter.html
- fin de journée (1h)

14 mars 2015:
- Il sera préférable à long terme de n'utiliser que le module Twython pour les api calls. Celui-ci est beaucoup plus complet et pourrait éventuellement supporter le stream API. Je considère donc de créer de nouveaux modèles pour Twitter, avec une toute nouvelle procédure de scrapping.
- En attendant, réparation provisoire de l'ancien protocole twitter. (fonctionnel, mais non-optimal et avec quelque bugs)
- Ajout de la liste des récents status postés dans la page d'acceuil Twitter
- ajout d'une section "Tw statuses" à la page admin
-fin de journée (8h)

23 mars 2015:
- Recherche de problèmes avec les scrappers de Facebook (module "resource" supporté seulement sous Unix)
- Réparation générale des templates de twitter
- Fin de journée (5h)

24 mars 2015:
- Installation des modules requis au scrapping de facebook (remplacement du module resource par psutil)
- Étude du fonctionnement de Fandjango et du Graph API de FB
- Fin de journée (1h)

3 avril 2015:
- Set up de fandjango, test des fonctionnalités
- Installation d'Apache (about time, I know...)
- Mise en place d'un certificat SSL via apache (got to learn first)
- Fin de journée (3h)

27 avril 2015:
- Fouillage dans la doc de google data, afin de faire fonctionner youtube
- Création d'un harvester, app sur mon compte,  etc.
- Test des fonctionnalités et débugging
- fin de journee (5h)

28 avril 2015:
- Continuation du 27 avril.
- Débug de la procédure d'ajout de nouveaux users
- Grattage de tete general
- fin de journée (5h)

29 - 30  et 31 avril 2015:
- Le scrapping de youtube fonctionne (presque) sans bugs.
- TODO:
	- debugger "video watch count"  et "view count" qui ne s'updatent pas
	- Mettre a jour le youtube player dans la page des videos (download des videos dans la db??)
	- Patching des erreurs occasionnelles (unicode errors, etc.)
- fins de journées (5h) (5h) (5h)

1 mai 2015:
- Rencontre avec Pier-Yves a propos de son bébé:
- Questions a poser:
	- Comment utiliser FanDjango?
	- Fandjango user
	- différentes versions de run_harvester ?
	- Download des videos youtube?
	- Serveur test Aspira
- Points retenus de la rencontre:
	- ID Facebook change risque de rendre la base de données actuelle obsolete au niveau des IDs
	- FanUser peut être importé de l'ancienne base de donnés
	- Probable nécéssité de recodder l'acces au token Facebook au complet
	- Connection au VPN du FSS requise pour accéder au SNH
- Listage des tâches a effectuer dans le cadre du stage

4 mai 2015:
- Installation de mon moniteur au bureau du GRCP
- Tentative d'obtention d'un token Facebook a partir d'un serveur de developpement
- debuggage et compréhension de Fandjango
- Fin de journée (5h)

5 mai 2015:
- Setup de django en mode SSL afin de pouvoir communiquer avec Facebook en https (difficultés rencontrées)
- Essai de fowarder les connections entrantes en utilisant stunel, sans succès.
- Essaie d'installer des modules django qui le font a ma place: Tous sont en python3... Je pense en customiser un pour mes besoins en python27
- Fin de journée (5h)

6, 7, 8 mai 2015:
- Implémentation du système de connection d'utilisateur Facebook (app, token, etc.)
- Changement du protocole d'appels au API par le harvester (retrait de fandjango)
- Essais et tests, implémentation manuelle des appels "batch"
- fins de journées (5h) (3h) (5h)

18 mai 2015:
- Rédaction de demande d'accès d'autorisations étendues pour l'app Facebook
- Amélioration de ma structure de debuggage
- Debuggage partiel de Facebook
- Fin de journée (6h)

19 mai 2015:
- Setup de la connection Web-VPN avec AnyConnect
- Débugging de Facebook, still...
- Fin de journée (5h)

20 - 21 mai 2015:
- Débugging de Facebook, fonctionnel, mise au point de détails
- Fin de journée (6h), (6h)

22 mai 2015:
- Fix d'un problème avec Unicode dans la DB SQL causant certain comments à être rejetés (caratères non-UTF-8)
- Remise au point de la compatibilité des méthodes Update_from_facebook() afin de collecter le plus de data possible.
- fin de journée (6h)

25 mai 2015:
- Graph API throttle les requests lorsque l'app en fait trop. Ma limite est tombée de 250 à moins de 50 par call.
- Ajustement automatique de la limite lorsqu'une erreur du genre survient.
- Acces au serveur-test du SNH. Tentative de setup de la base de donné MySQL, afins d'y avoir acces à distance, faire des backups, etc.
- fin de journée (7h)

26 mai 2015:
- Connection à distance à la base de données du serveur-test. 
- Setup adéquat de Apache sur le serveur-test et debuggage du serveur
- Serveur-test en ligne!
- fin de journée (8h)

28 mai 2015:
- Setup des harvesters sur le serveur-test (Youtube, Facebook et Twiter) et tests
- Mise en place des cron-jobs
- tests
- fin de journée (6h)

30 mai 2015:
- Fix de la procédure de paging de Twitter
- Tests
- fin de journée (6h)

1 juin 2015:
- Optimisation du code twitter, afin d'utiliser toute les ressources disponibles pour chaque app et accélérer la collecte
- fin de journée (6h)

2 juin 2015:
- Optimisation de l'utilisation des ressources Twitter
- Code d'un algo permettant de collecter les infos de tout les utilisateurs (pas juste ceux harvestés)
- fin de journée (6h)

3 juin 2015:
- Update du server-test, mise en place d'un cronjob a chaque 30 min pour twitter.
- Entré de la liste des utilisateurs (membres des parlements Européens, 572 utilisateurs)
- Fonctionnement toute la nuit, évaluation des résultats demain.
- fin de journée (7h)

4 juin 2015:
- Évaluation de la performance du scrapper de Twitter a grande échelle
- Réglage de petits bugs
- Sauvegarde de la base de donnée
- Augmentation du temps entre chaque cronjob (a chaque 30 min est trop intense pour le serveur-test) Évalué plutot a chaque 2 heures.
- fin de journée (5h)

5 juin 2015:
- Évaluation de la performance de Facebook sur le serveur-test
- Prise en charge de petits bugs aléatoires
- Commencement d'un diagramme UML des DB models, afin d'avoir une présentation croncrete des changements a apporter en cours d'été (style avant/apres de la DB)
- fin de journée (6h)

8 juin 2015:
- Visualisation des logfiles a partir de la section admin du SNH (web)
- Optimisation de Facebook (certains champs ne s'updatent pas parce que la procédure de Fb a changé)
- fin de journée (6h)

9 juin 2015:
- patching de facebook et Twitter
- Test de Youtube (Data api v2 est désuet... Il faut réimplémenter du nouveau code. Il n'existe pas de module tout-fait)
- lecture de la documentation de gdata
- fin de journée (5h)

10 juin 2015:
- lecture de documentation sur youtube
- tests de fonctionnalités des code samples offerts par google
- fin de journée (5h)

11 juin 2015:
- Rencontre avec Thierry, Mickael et Pier-Yves:
	- Acces aux serveurs de production
	- Discussion de l'avancement du stage avec Thierry
- Connection SSH au serveur de production
- Évaluation de la taille de la base de donné a receuillir
- Fin de journée (5h)

12 juin 2015:
- Connection à la base de donné du serveur Prod
- Backup des donnés legacy
- Remise en marche du serveur-test (dû faire du ménage. STREAMR prend beaucoup de place, devrait être cleané)
- fin de journée (6h)

15 juin 2015:
- Test et implémentation du nouvel API de Youtube en local
- lecture de documentation
- fin de journée (6h)

16 juin 2015:
- Recherche d'un module en python facilitant l'usage du nouvel api de Youtube
- Aucune trouvée. Commencement de la création d'une classe avec les fonction pertinentes.
- fin de journée (6h)

17 juin 2015:
- Rencontre a propos de la migration du serveur de production
- Continuation du developpement de youtube
- Il semble que les captions (sous-titres) des videos sont uniquement accessibles par le propriétaire... problème ahead.
- fin de journée (6h)

18 juin 2015:
- Travail sur mon youtube wrapper. L'authentification oauth2 ne sert a rien. Requetes en mode public seulement
- Utilisation d'autres API: youtube-dl qui permet de downloader des videos a partir de leur URL et d'en extraire les captions
- fin de journée (7h)

19,21,22,23,24,26,27,29 juins:
- Développement et implémentation du "YoutubeV3Wrapper" comme client du YoutubeHarvester
- Prise en charge du download des fichiers videos (basse qualité afin d'être conservatif sur l'espace) et des sous-titres lorsque disponibles.
- Débugging, etc.
- Changement de la structure d'update des YTUsers. Les "channels" peuvent être updaté en chunk (50 par api call). Même chose pour les YTVideos.
- TODO: Créer des profils Google+ pour les informations d'utilisateurs. Le API de Youtube ne retourne que des infos sur un "channel" donné.
  Un utilisateur Google+ peut potentiellement avoir plusieurs channels, ce qui change la structure profonde du SNH. Pour cela, il faudrait implémenter un
  scrapper différent pour Google+.
- fins de journés (6h)(5h)(4h)(7h)(6h)(5h)(6h)(8h)

30 juin 2015: 
- Déploiement du code sur le serveur de production.
- Combat sans mercie avec Apache et les virtualhosts.
- fin de journée (7h)

1 juillet 2015:
- Mise e place des harvesters "Qc2014", "Ontario 2014" et "Alberta 2015" sur le serveur de production
- Backup de la DB à son état origninal
- fin de journée (4h)

2 juillet 2015:
- Assemblée des membres du GRCP (présentation comme stagiaire)
- tests des scrappers Facebook et Twitter: DB CAPPE EN 10 MIN!
- Identification du problème: La table FBResult, qui a elle-seule prend 1000x plus de place que toute les autres tables.
- Utilisation de la magie (et des symlinks...) pour que cette table soit sur un emplacement différent, plus volumineux.
- fin de journée (7h)

3 juillet 2015:
- Entretien avec Mickael:
	- TODO: collecter les données RAW pour "#abvote". période 7 avril 2015 - 24 mai 2015
	- TODO: customizer le download en .csv des données Twitter, afin de fournir plus de data dans un même document (redondance...) 
	- TODO: si possible, faire la collecte de tout les retweets des tweets principaux lors d'un harvest
- Correction de la procédure de collecte de Twitter, élimination des cas de famine lorsque plusieurs harvesters sont utilisés
- fin de journée (6h)

6 juillet 2015:
- Test plus exhaustif de twitter
- Implémentation d'une option 'collecte des raw-statuses', soit des tweets à l'état brut en dict. (à la demande de Mickael)
- Problème de connection à Twitter. (L'université me bloque l'accès? ou twitter?)
- Test sur serveur de prod et patchs
- Fin de journée (7h)

7 juillet 2015:
- Rencontre mi-stage
- Revue avec Thiery de la prochaine priorité de développement (mise à niveau Python3 du code)
- Exploration des settings de Apache, avec mod-wsgi et un virtualenv en python3 sous Linux
- fin de journée (6h)

8 juillet 2015:
- Transfert de fichiers-backups SQL sur mnt/video/ (Disque plein, encore).
- Suspendu la procédure automatique de backup 'automysqlbackup' d'ici à ce qu'on ai plus d'espace
- Training avec mod-wsgi et apache. Succès d'un setup de wsgi sous un virtualenv python3.4 et serving de fichiers.
- fin de journée (8h)

9-10 juillet 2015:
- Migration du serveur de production avec Francois Vaillancourt vers Ubuntu 14.04
- Débug de la procédure Facebook, qui semble planter apres un certain temps de collecte sur le serveur.
- Patching divers.

13 juillet 2015:
- Collecte des donnés brutes de #abvote pour Mickael.
- Correction d'une erreur dans la procédure de collecte des donnés brutes de twitter.
- fin de journée (6h)

14 juillet 2015:
- Création d'un script spécialisé pour collecter les tweets par hashtags. Celui-ci utilise la page web de twitter comme collecte préliminaire (ids)
- Collection de abvote (~25000 tweets)
- fin de journée (7h)

15 juillet 2015:
- Étude du fonctionnement des DNS, subdomains et virtualhosts avec Apache.
- Courriel à François Vaillancourt pour mettre a jour l'adressage des sous-domaines qc, fr et francedebat sur le nouveau serveur de production
- fin de journée (4h)

16 juillet 2015:
- Implémentation du script pour collecter les hashtags de twitter a partir de la page web (html) dans la procédure de collecte
- TODO:
	- Implementer la possibilité de downloader les listes de tweets en format json à partir du 'raw data'
	- Donner le choix a l'utilistateur de downloader en .csv ou en .json les champs voulus. (sélection préalable dans l'interface)
- fin de journée (6h)

20 juillet 2015:
- Reformatage du code pour la procédure de collecte des hashtags à partir d'une page html. Débugging
- Fin de journée (6h)

21 juillet 2015:
- Correction de bugs associés à Twitter et Facebook
- Tests
- fin de journée (5h)

22 juillet 2015:
- Continuation des tests
- Réparation de l'affichage du "hit count" pour les recherches par mot-clefs de Twitter ~3h30
- Vérification que chaque TWUser est collecté comme il faut (pas de famine)
- Fin de journée (7h)

23 juillet 2015:
- Implémentation d'un lien pour downloader les tweets en format JSON, à partir d'Aspira.
- Débuggage de Facebook. Le serveur fait un memory overflow pendant le traitement des "fbresults". Changement de la stratégie de traitement
- Téléchargement en local de la table fbResult, afin de débugger en local.
- Fin de journée (7h)

24 juillet 2015:
- Entretien avec Mickael. Points a aborder:
	- Pages Facebook vs Comptes Facebook. (https://www.facebook.com/pages/Mike-Schreiner/121887537855675?fref=ts vs https://www.facebook.com/mike.schreiner?ref=ts&fref=ts)
	- Montrer le progrès avec les hashtags. Download en JSON, option de collecte en rawdata, scrapping en HTML légal?
	- Principe de redondance des donnés. (Taille de la DB vs vitesse de traitement)
	- MongoDB VS MySQL: Redondance, indexage, etc. Un bon exemple est la table FbResult (17.9 Gb)
	- Livestream Twitter vraiement nécéssaire? En python 3.4? (temps de développement, pertinence vis-à-vis des besoins, peu d'intérêt de Thierry)
	- Nouvelles capacités serveur (600 Gb plutot que 200Gb). Coûts.
	- Présentation orale de stage. Superviseur invité.
- temps estimé de collecte twitter et couriels
-fin de journée (6h)

27 - 28 juillet 2015:
- Debug de la procédure de traitement des FBResults (multithread) qui est mal optimisée pour une grosse Database
- Début de code d'une option de selection des champs lors du download en CSV des tweets. 
- Débugging et compréhjension de la structure javascript et des 'tableTools' utilisées par Pier-Yves. Celles-ci sont trop limitées pour nos 
besoin. J'implémente une django-view à part pour cette fonction.
- fins de journées (4h) (6h)

29